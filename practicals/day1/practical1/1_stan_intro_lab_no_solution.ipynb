{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5e9bc012-d0f5-414d-a5de-5ec9f3ea84ce",
      "metadata": {
        "id": "5e9bc012-d0f5-414d-a5de-5ec9f3ea84ce"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/MLGlobalHealth/StatML4PopHealth/blob/main/practicals/day1/practical1/1_stan_intro_lab_no_solution.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7230ef-3ba0-425c-9976-3df13ff90e85",
      "metadata": {
        "id": "fc7230ef-3ba0-425c-9976-3df13ff90e85"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/imperial.png\" width=\"250\" vspace=\"8\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/mlgh.png\" width=\"220\" hspace=\"50\" vspace=\"5\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/MLGlobalHealth/StatML4PopHealth/main/practicals/resources/logos/ammi.png\" width=\"190\"/>\n",
        "\n",
        "<font size=\"6\">Modern Statistics and Machine Learning\n",
        "for Population Health in Africa </font>\n",
        "\n",
        "<font size=\"4\">24th - 28th March 2025</font>\n",
        "\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efa1e90f-1f79-4770-95ff-a29d741adbcd",
      "metadata": {
        "id": "efa1e90f-1f79-4770-95ff-a29d741adbcd"
      },
      "source": [
        "# Computing lab: Stan Basics\n",
        "## Modern Statistics and Machine Learning for Population Health in Africa\n",
        "#### Tristan Naidoo and Sahoko Ishida\n",
        "(With thanks to Yu Chen and Oliver Ratmann for the content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f27bd6a3-22fd-4503-96aa-36d309f94704",
      "metadata": {
        "id": "f27bd6a3-22fd-4503-96aa-36d309f94704"
      },
      "source": [
        "## Study objectives\n",
        "\n",
        "Hello all!\n",
        "\n",
        "By the end of this lab,\n",
        "\n",
        "- you will understand the key benefits of modern statistical computing languages such as `Stan`; and\n",
        "- you will have installed the `Stan` software within `Python`, via `cmdstan`; and\n",
        "- you will be familiar with a typical analysis workflow using `Stan`, and associated `Python` commands."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b6d745-0967-412e-81cc-4618a5c57f38",
      "metadata": {
        "id": "e2b6d745-0967-412e-81cc-4618a5c57f38"
      },
      "source": [
        "## Why Stan?\n",
        "\n",
        "`Stan`\n",
        "\n",
        "- is an open-source statistical inference software, which implements gradient-based MCMC to sample from posterior distributions.\n",
        "- allows us to focus on statistical modelling, rather than implementing inference algorithms.\n",
        "- algorithms are implemented in \\textsl{C++}, and can be accessed through interfaces like `CmdStanPy` and `PyStan` in `Python`.\n",
        "- Bayesian models are written in text files.\n",
        "\n",
        "There are several modern alternatives to `Stan`, including\n",
        "\n",
        "- [numpyro](https://num.pyro.ai/en/latest/index.html#introductory-tutorials); and\n",
        "- [TMD](https://github.com/kaskr/adcomp/wiki); and\n",
        "- [Nimble](https://r-nimble.org)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fddbdf8-3946-4e52-b98d-d50ac2590917",
      "metadata": {
        "id": "2fddbdf8-3946-4e52-b98d-d50ac2590917"
      },
      "source": [
        "## Installation\n",
        "For this course we will use `CmdStanPy`, which is a recently developed lightweight alternative to `PyStan` for interfacing with Stan in Python. The functions to compile, run, and access the output of Bayesian inference algorithms are very similar, but not identical to those in the `PyStan` package. However, both `CmdStanPy` and `PyStan` read exactly the same `Stan` model files, and so `CmdStanPy` is an excellent alternative if you run into installation issues with `PyStan`, or if you would rather work with the most recent `Python` interface to `Stan`'s algorithms.\n",
        "\n",
        "Throughout this course, we will work in Google Colab. The steps to install `CmdStanPy` and `CmdStan` in your Colab instance are provided below.\n",
        "\n",
        "If you would like to install `CmdStanPy` and `CmdStan` on your local machine please follow the instructions provided [here](https://mc-stan.org/cmdstanpy/installation.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82f22d9a-be5d-4880-a7d2-b83986d4025b",
      "metadata": {
        "id": "82f22d9a-be5d-4880-a7d2-b83986d4025b"
      },
      "source": [
        "#### Step 1: Install the python package `CmdStanPy`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0a500343-48c2-4ae7-a1a6-4835681d543e",
      "metadata": {
        "id": "0a500343-48c2-4ae7-a1a6-4835681d543e",
        "outputId": "8034ab7c-b169-461e-b1f9-00e4f4977041",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cmdstanpy==1.2.5 in /usr/local/lib/python3.11/dist-packages (1.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from cmdstanpy==1.2.5) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from cmdstanpy==1.2.5) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from cmdstanpy==1.2.5) (4.67.1)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from cmdstanpy==1.2.5) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->cmdstanpy==1.2.5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->cmdstanpy==1.2.5) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->cmdstanpy==1.2.5) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->cmdstanpy==1.2.5) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade cmdstanpy==1.2.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d343cd4-97b4-4f5f-ae55-862641359ea3",
      "metadata": {
        "id": "7d343cd4-97b4-4f5f-ae55-862641359ea3"
      },
      "source": [
        "#### Step 2: Install `CmdStan`\n",
        "\n",
        "We install the pre-built colab CmdStan binary because its faster than compiling from source via `install_cmdstan()` function. If you are installing locally please download the appropriate binary or alternatively use `install_cmdstan()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ZbCSEXZff535",
      "metadata": {
        "id": "ZbCSEXZff535"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import urllib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "30cd619e-0afd-4839-b7c3-1a913b8b5275",
      "metadata": {
        "id": "30cd619e-0afd-4839-b7c3-1a913b8b5275"
      },
      "outputs": [],
      "source": [
        "tgz_file = 'colab-cmdstan-2.36.0.tar.gz'\n",
        "tgz_url = 'https://github.com/stan-dev/cmdstan/releases/download/v2.36.0/colab-cmdstan-2.36.0.tgz'\n",
        "if not os.path.exists(tgz_file):\n",
        "    urllib.request.urlretrieve(tgz_url, tgz_file)\n",
        "    shutil.unpack_archive(tgz_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8ef840a-81f6-4fd5-acb7-0fbf20f58bea",
      "metadata": {
        "id": "e8ef840a-81f6-4fd5-acb7-0fbf20f58bea"
      },
      "source": [
        "We also need to install an additional linux dependency that is missing on the machine that our colab instance is running on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3e653439-7603-4f50-815b-2d7a0abaeb49",
      "metadata": {
        "id": "3e653439-7603-4f50-815b-2d7a0abaeb49",
        "outputId": "ce64f809-501a-4384-960e-9301e0bc52a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libtbb2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 101 kB of archives.\n",
            "After this operation, 313 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtbb2 amd64 2020.3-1ubuntu3 [101 kB]\n",
            "Fetched 101 kB in 0s (318 kB/s)\n",
            "Selecting previously unselected package libtbb2:amd64.\n",
            "(Reading database ... 126209 files and directories currently installed.)\n",
            "Preparing to unpack .../libtbb2_2020.3-1ubuntu3_amd64.deb ...\n",
            "Unpacking libtbb2:amd64 (2020.3-1ubuntu3) ...\n",
            "Setting up libtbb2:amd64 (2020.3-1ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt install libtbb2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4f05604-898f-48fb-870f-d9d75ae5d2b9",
      "metadata": {
        "id": "c4f05604-898f-48fb-870f-d9d75ae5d2b9"
      },
      "source": [
        "#### Step 3: Specify `CmdStan` path\n",
        "We set the `CmdStan` path using an environment variable. This tells your machine where to look for `CmdStan`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "25d1311f-16ad-48d1-9ea3-a8625e2b4a93",
      "metadata": {
        "id": "25d1311f-16ad-48d1-9ea3-a8625e2b4a93"
      },
      "outputs": [],
      "source": [
        "os.environ['CMDSTAN'] = './cmdstan-2.36.0'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "165d4c1f-aba7-4ecd-9727-cd8d24ddc8a6",
      "metadata": {
        "id": "165d4c1f-aba7-4ecd-9727-cd8d24ddc8a6"
      },
      "source": [
        "Next, we check `CmdStan` path. This should be the same as what is specified above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a3717b2c-6e41-4edd-be82-1ff8f5b58006",
      "metadata": {
        "id": "a3717b2c-6e41-4edd-be82-1ff8f5b58006",
        "outputId": "179644ee-afea-4799-d61a-90315630480a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cmdstan-2.36.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from cmdstanpy import CmdStanModel, cmdstan_path\n",
        "cmdstan_path()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e4b6faa-e2d0-4048-b8ad-eef080f3e994",
      "metadata": {
        "id": "2e4b6faa-e2d0-4048-b8ad-eef080f3e994"
      },
      "source": [
        "## Hello world example, using `CmdStanPy`\n",
        "\n",
        "Let us start with a very simple example to become familiar with `Stan`.\n",
        "\n",
        "We aim to fit a normal model to 100 data points $y_i, i=1,\\dotsc,n=100$, and estimate the joint posterior distribution of the mean and standard deviation numerically with Stan,\n",
        "\n",
        "\\begin{align*}\n",
        "&y_{i} \\sim \\text{Normal}(\\mu, \\sigma^2) \\\\\n",
        "& \\mu \\sim \\text{Normal}(0,100)\\\\\n",
        "& \\sigma\\sim \\text{Half-Cauchy}(0,1).\n",
        "\\end{align*}\n",
        "\n",
        "Let us compile the corresponding `Stan` model and run two Hamiltonian Monte Carlo (HMC) chains for 4,000 iterations each, including 1,000 warmup iterations.\n",
        "\n",
        "Every `Stan` model files is structured in terms of the following blocks:\n",
        "\n",
        "- `data` block: specifies data required to fit the model\n",
        "- `transformed data` block: specifies temporary transformations of the data, e.g. QR decomposition of $X$; variables that do not change\n",
        "- `parameters` block: specifies all parameters that are fitted; cannot be assigned values directly\n",
        "- `transformed parameters` block: optional transformations of parameters, e.g. risk differences\n",
        "- `model` block: specifies the model in terms of likelihood and priors\n",
        "- `generated quantities` block: quantities that depend on parameters and data, and do not affect inference\n",
        "\n",
        "Here is a simple implementation of our Hello World normal model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2a1964be-692d-4594-841c-ccc46965bb7f",
      "metadata": {
        "id": "2a1964be-692d-4594-841c-ccc46965bb7f"
      },
      "outputs": [],
      "source": [
        "# Hello World normal model\n",
        "model1_text = \"\"\"\n",
        "data{\n",
        "    int<lower=1> N;\n",
        "    array [N] real y;\n",
        "}\n",
        "parameters{\n",
        "    real mu;\n",
        "    real<lower=0> sigma;\n",
        "}\n",
        "model{\n",
        "    sigma ~ cauchy( 0 , 1 );\n",
        "    mu ~ normal( 0 , 10 );\n",
        "    y ~ normal( mu , sigma );\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84726184-53c3-4c58-8ab5-d871f174158c",
      "metadata": {
        "id": "84726184-53c3-4c58-8ab5-d871f174158c"
      },
      "source": [
        "To use this model in `Python`, we start by loading up our `Python` packages.\n",
        "If you are running this notebook on Google colab the packages we need are included by default. If you are running this notebook locally please install any missing packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3c41f2d7-d62d-469e-ad94-1c420ad01931",
      "metadata": {
        "id": "3c41f2d7-d62d-469e-ad94-1c420ad01931"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "import arviz as az\n",
        "from cmdstanpy import CmdStanModel\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.getLogger(\"cmdstanpy\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7jJESa0siEie",
      "metadata": {
        "id": "7jJESa0siEie",
        "outputId": "73a4ed70-bf5e-4852-888b-b2857fec1db8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8270eb84-2d97-4ecd-bbf2-17705ab50bbe",
      "metadata": {
        "id": "8270eb84-2d97-4ecd-bbf2-17705ab50bbe"
      },
      "outputs": [],
      "source": [
        "# Adjust this as required - this is where your output will be stored.\n",
        "output_dir = Path(*[\"drive\", \"MyDrive\", \"StatML4PopHealth\", \"output\"])\n",
        "output_dir.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89d6624c-b6ae-44d8-8586-b2661b5b0cf5",
      "metadata": {
        "id": "89d6624c-b6ae-44d8-8586-b2661b5b0cf5"
      },
      "source": [
        "Now, please complete the following code block to sample from the joint posterior associated with the Hello World model for 4,000 iterations including 1,000 iterations of warmup. Setup two Hamiltonian Monte Carlo chains and initialise the two chains at $(\\mu=1, \\sigma=2)$ and $(\\mu=-1, \\sigma=0.5)$:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "45d46041-4523-4152-a1c6-d4714283d270",
      "metadata": {
        "id": "45d46041-4523-4152-a1c6-d4714283d270"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "np.random.seed(10680)  # Use your birth date\n",
        "\n",
        "# Generate random normal data\n",
        "y = np.random.normal(loc=0, scale=1, size=100)\n",
        "\n",
        "# Create data dictionary for Stan\n",
        "stan_data = {\n",
        "    'N': len(y),\n",
        "    'y': y\n",
        "}\n",
        "\n",
        "# Write the Stan model to a file\n",
        "# CmdStanPy requires the model to be written to a file\n",
        "model1_filename = output_dir.joinpath(\"helloworld.stan\")\n",
        "with open(model1_filename, \"w\") as f:\n",
        "    f.write(model1_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XkT4-qf1jn1N",
      "metadata": {
        "id": "XkT4-qf1jn1N"
      },
      "outputs": [],
      "source": [
        "# Compile the Stan model using CmdStanPy\n",
        "model1_compiled = CmdStanModel(stan_file=model1_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dOyBYDThjf5Y",
      "metadata": {
        "id": "dOyBYDThjf5Y"
      },
      "outputs": [],
      "source": [
        "# Sample from the joint posterior of the Hello World model using CmdStanPy\n",
        "model1_fit = model1_compiled.sample(\n",
        "    data=stan_data,\n",
        "    seed=123,\n",
        "    chains=2,\n",
        "    parallel_chains=2,\n",
        "    iter_warmup=1000,\n",
        "    iter_sampling=4000,\n",
        "    refresh=500,  # Print update every 500 iterations\n",
        "    save_warmup=True,\n",
        "    inits=[{'mu': 1, 'sigma': 2},\n",
        "           {'mu': -1, 'sigma': 0.5}]  # Initial values for the chains\n",
        ")\n",
        "\n",
        "# -- You don't need to do this in the TODO chunks below, it's just an example\n",
        "# in case you want to save your output object\n",
        "# Save the output to a pickle file\n",
        "output_fit_file = output_dir.joinpath(\"model1_fit_cmdstanpy.pkl\")\n",
        "with open(output_fit_file, \"wb\") as f:\n",
        "    pickle.dump(model1_fit, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ccbcfc-e5ae-4cd8-8033-4c5c81d252b4",
      "metadata": {
        "id": "87ccbcfc-e5ae-4cd8-8033-4c5c81d252b4"
      },
      "source": [
        "Next, we explore the following code snippets that provide key functions to assess the Monte Carlo output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02c2d76c-d794-4c40-bc7e-bf07eba7b325",
      "metadata": {
        "id": "02c2d76c-d794-4c40-bc7e-bf07eba7b325"
      },
      "outputs": [],
      "source": [
        "# -- You don't need to do this in the TODO chunks below, it's just an example\n",
        "# in case you want to save your output object\n",
        "# Load the output from the pickle file saved earlier\n",
        "with open(output_fit_file, \"rb\") as f:\n",
        "    model1_fit = pickle.load(f)\n",
        "\n",
        "# Specify the parameters you want to check\n",
        "model1_pars = [\"mu\", \"sigma\"]\n",
        "model1_pars_with_lp = model1_pars + [\"lp__\"]\n",
        "\n",
        "# Get summary of the specified parameters\n",
        "model1_summary = model1_fit.summary(sig_figs=4)\n",
        "model1_summary.loc[model1_pars_with_lp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sH0ksbedAjW2",
      "metadata": {
        "id": "sH0ksbedAjW2"
      },
      "outputs": [],
      "source": [
        "# We can also use a library to get this summary\n",
        "# Convert the CmdStanPy model fit to ArviZ InferenceData\n",
        "model1_fit_az_idata = az.from_cmdstanpy(model1_fit, save_warmup=True)\n",
        "\n",
        "# arviz parses our data into groups based on our fit object\n",
        "model1_fit_az_idata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SR0F1tA8lHf6",
      "metadata": {
        "id": "SR0F1tA8lHf6"
      },
      "outputs": [],
      "source": [
        "# Get summary statistics, including 2.75% and 97.5% quantiles\n",
        "summary_stats = az.summary(model1_fit_az_idata,\n",
        "                           var_names=model1_pars,\n",
        "                           group=\"posterior\",\n",
        "                           hdi_prob=0.95,\n",
        "                           kind=\"all\"# 95% highest density interval\n",
        "                           )\n",
        "\n",
        "summary_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49754168-b17a-4d15-aab4-005f1e532a76",
      "metadata": {
        "id": "49754168-b17a-4d15-aab4-005f1e532a76"
      },
      "outputs": [],
      "source": [
        "# To plot traces and assess convergence, extract\n",
        "# Monte Carlo samples including warmup in default\n",
        "# array format that keeps all chains separate\n",
        "\n",
        "# It's often helpful to plot the log posterior density too. Since it is a\n",
        "# sample stat and arviz can only access one group at a time, we will manually\n",
        "# add it to make it easier to view everything together\n",
        "model1_fit_az_idata[\"posterior\"][\"lp\"] = model1_fit_az_idata[\"sample_stats\"][\"lp\"]\n",
        "model1_pars_with_lp = model1_pars + [\"lp\"]\n",
        "\n",
        "# Print summary of the parameters\n",
        "summary_stats = az.summary(model1_fit_az_idata,\n",
        "                           var_names=model1_pars_with_lp,\n",
        "                           group=\"posterior\",\n",
        "                           hdi_prob=0.95,\n",
        "                           kind=\"all\"\n",
        "                          )\n",
        "\n",
        "summary_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe566464-6c3d-4eaa-a6c1-6f45c15cdcb0",
      "metadata": {
        "id": "fe566464-6c3d-4eaa-a6c1-6f45c15cdcb0"
      },
      "outputs": [],
      "source": [
        "# Plot trace for parameters (mu, sigma, and lp)\n",
        "# different colours are different chains\n",
        "az.plot_trace(model1_fit_az_idata,\n",
        "              filter_vars=\"like\",\n",
        "              var_names=model1_pars_with_lp,\n",
        "              combined=False,\n",
        "              compact=False,\n",
        "              kind=\"trace\",\n",
        "              figsize=(11, 10))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Save the plot to a PDF file\n",
        "plt.savefig(output_dir.joinpath(\"model1_cmdstanpy_trace_arviz.pdf\"),\n",
        "            format=\"pdf\",\n",
        "            bbox_inches=\"tight\")\n",
        "\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c245a7f0-f3bd-4788-983a-5e2e8290e2b6",
      "metadata": {
        "id": "c245a7f0-f3bd-4788-983a-5e2e8290e2b6"
      },
      "outputs": [],
      "source": [
        "# Extract the posterior samples excluding warmup\n",
        "# Make the pairs plot (including log-posterior)\n",
        "az.plot_pair(model1_fit_az_idata,\n",
        "             var_names=model1_pars_with_lp,\n",
        "             marginals=True,\n",
        "             figsize=(13, 8))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.savefig(output_dir.joinpath(\"model1_cmdstanpy_pairsplot.pdf\"),\n",
        "            format=\"pdf\", bbox_inches=\"tight\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a8fcad8-75ea-436e-89bf-bf80d1d07c29",
      "metadata": {
        "id": "2a8fcad8-75ea-436e-89bf-bf80d1d07c29"
      },
      "outputs": [],
      "source": [
        "# To manipulate the posterior Monte Carlo samples after warmup we\n",
        "# typically prefer to extract the samples as a DataFrame (excluding warmup)\n",
        "posterior_df = model1_fit_az_idata.posterior.to_dataframe()\n",
        "posterior_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39bb5f69-5ecc-411d-b44a-28bd0ee94299",
      "metadata": {
        "id": "39bb5f69-5ecc-411d-b44a-28bd0ee94299"
      },
      "source": [
        "## The flat priors example\n",
        "\n",
        "Let us adapt the Hello World example a wee bit, so that we can explore how a non-successful numerical inference run with `Stan` might look like.\n",
        "\n",
        "We will engineer a statistical problem that is very hard to sample from, due to unsuitable prior specifications. First, we will reduce the data to just two data points. Second, we will specify unbounded uniform priors are specified for both $\\mu$ and $\\sigma$, which says that prior values close to infinity are as likely as close to zero.\n",
        "\n",
        "The learning outcome here is that a common reason why `Stan` fails to sample from a joint posterior is that the priors are misspecified as either way too wide, or way too narrow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u8llCGdaSlAB",
      "metadata": {
        "id": "u8llCGdaSlAB"
      },
      "outputs": [],
      "source": [
        "# Data now consist of TWO data points ONLY\n",
        "y = np.array([-1, 1])\n",
        "stan_data = {\n",
        "    'N': len(y),\n",
        "    'y': y\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f787368b-819a-4900-ad7a-ee852efb8b5e",
      "metadata": {
        "id": "f787368b-819a-4900-ad7a-ee852efb8b5e"
      },
      "outputs": [],
      "source": [
        "# Define the Stan model with flat priors on mu and sigma\n",
        "model2_text = \"\"\"\n",
        "data {\n",
        "    int<lower=1> N;\n",
        "    array [N] real y;\n",
        "}\n",
        "parameters {\n",
        "    real mu;\n",
        "    real<lower=0> sigma;\n",
        "}\n",
        "model {\n",
        "    y ~ normal(mu, sigma);\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70aec27c-81ad-4f45-a6c9-a08c9e5f0bfe",
      "metadata": {
        "id": "70aec27c-81ad-4f45-a6c9-a08c9e5f0bfe"
      },
      "source": [
        "Now, let us compile the `Stan` model file, and run `Stan`'s Hamiltonian Monte Carlo algorithm for $1000$ iterations that include $400$ warmup iterations. Setup two Hamiltonian Monte Carlo chains and initialise both chains at $(\\mu=0, \\sigma=1)$. Then make a trace plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "959ddf37-1af0-42b8-ab25-526e291cf71c",
      "metadata": {
        "id": "959ddf37-1af0-42b8-ab25-526e291cf71c"
      },
      "outputs": [],
      "source": [
        "# Write the Stan model to a file\n",
        "model2_filename = \"model2.stan\"\n",
        "with open(model2_filename, 'w') as f:\n",
        "    f.write(model2_text)\n",
        "\n",
        "# Compile the Stan model using CmdStanPy\n",
        "model2_compiled = CmdStanModel(stan_file=model2_filename)\n",
        "\n",
        "# Sample from the posterior distribution\n",
        "model2_fit = model2_compiled.sample(\n",
        "    data=stan_data,\n",
        "    seed=123,\n",
        "    chains=2,\n",
        "    parallel_chains=2,\n",
        "    iter_sampling=1400,\n",
        "    iter_warmup=400,\n",
        "    refresh=500,\n",
        "    save_warmup=True,\n",
        "    inits=[{'mu': 0, 'sigma': 1},\n",
        "          {'mu': 0, 'sigma': 1}]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rIZoqdzZRXrY",
      "metadata": {
        "id": "rIZoqdzZRXrY"
      },
      "outputs": [],
      "source": [
        "# Create an ArviZ InferenceData object\n",
        "model2_fit_az_idata = az.from_cmdstanpy(model2_fit, save_warmup=True)\n",
        "\n",
        "# Print the summary of the sampling results\n",
        "model2_pars = [\"mu\", \"sigma\"]\n",
        "\n",
        "summary_stats = az.summary(model2_fit_az_idata,\n",
        "                           var_names=model2_pars,\n",
        "                           group=\"posterior\",\n",
        "                           hdi_prob=0.95,\n",
        "                           kind=\"all\")\n",
        "\n",
        "summary_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35868a1-bd01-4ddb-8903-a9b14ad7a1e9",
      "metadata": {
        "id": "c35868a1-bd01-4ddb-8903-a9b14ad7a1e9"
      },
      "outputs": [],
      "source": [
        "# Trace plots\n",
        "az.plot_trace(model2_fit_az_idata,\n",
        "              filter_vars=\"like\",\n",
        "              var_names=[\"mu\", \"sigma\"],\n",
        "              combined=False,\n",
        "              compact=False,\n",
        "              kind=\"trace\",\n",
        "              figsize=(11, 10))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Save the plot to a PDF file\n",
        "plt.savefig(output_dir.joinpath(\"model2_cmdstanpy_trace_arviz.pdf\"),\n",
        "            format=\"pdf\",\n",
        "            bbox_inches=\"tight\")\n",
        "\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31sh97P5F-f9",
      "metadata": {
        "id": "31sh97P5F-f9"
      },
      "source": [
        "For comparison, let us now place weakly informative priors on $\\mu$ and $\\sigma$, and repeat the excercise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e3c0597-7378-401d-8886-eed5b7723024",
      "metadata": {
        "id": "5e3c0597-7378-401d-8886-eed5b7723024"
      },
      "outputs": [],
      "source": [
        "# Specify Stan model with weakly informative prior on mu and sigma\n",
        "model3_text = \"\"\"\n",
        "data{\n",
        "    int<lower=1> N;\n",
        "    array [N] real y;\n",
        "}\n",
        "parameters{\n",
        "    real mu;\n",
        "    real<lower=0> sigma;\n",
        "}\n",
        "model{\n",
        "    sigma ~ cauchy( 0 , 1 );\n",
        "    mu ~ normal( 0 , 10 );\n",
        "    y ~ normal( mu , sigma );\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U7G28xV-O_ex",
      "metadata": {
        "id": "U7G28xV-O_ex"
      },
      "outputs": [],
      "source": [
        "# TODO: Write the Stan model to a file\n",
        "\n",
        "# TODO: Compile the Stan model using CmdStanPy\n",
        "\n",
        "# TODO: Sample from the posterior distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ruAepCTSDDA",
      "metadata": {
        "id": "3ruAepCTSDDA"
      },
      "outputs": [],
      "source": [
        "# TODO: Create an ArviZ InferenceData object\n",
        "\n",
        "# TODO: Print the summary of the sampling results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc114a3e-2c75-4b0b-a9e9-b4c246ac1c6a",
      "metadata": {
        "id": "bc114a3e-2c75-4b0b-a9e9-b4c246ac1c6a"
      },
      "outputs": [],
      "source": [
        "# TODO: Trace plots\n",
        "\n",
        "# TODO: Save the plot to a PDF file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EEKXvE5WSVxv",
      "metadata": {
        "id": "EEKXvE5WSVxv"
      },
      "source": [
        "## The unidentifiable parameters example\n",
        "\n",
        "Finally, we will adapt the Hello World example slightly differently, again to explore how a non-successful numerical inference run with `Stan` might look like in the case when two parameters cannot be estimated from the data, only their combination. To engineer this situation, we will introduce two unknown random variables $\\alpha_1$ and $\\alpha_2$, and say that the sum of both is the mean in our Hello World normal model.\n",
        "\n",
        "The learning outcome here is that a common reason why `Stan` fails to sample from a joint posterior is that the parameters in a model are highly correlated, and there are multiple equally likely solutions under the model as specified.\n",
        "\n",
        "Let us start with unbounded uniform priors specified on $\\alpha_1$ and $\\alpha_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w426Sv4jSeTR",
      "metadata": {
        "id": "w426Sv4jSeTR"
      },
      "outputs": [],
      "source": [
        "# specify Stan model with unidentifiable parameters and flat prior\n",
        "model4_text = \"\"\"\n",
        "data{\n",
        "    int<lower=1> N;\n",
        "    array [N] real y;\n",
        "}\n",
        "parameters{\n",
        "    real alpha1;\n",
        "    real alpha2;\n",
        "    real<lower=0> sigma;\n",
        "}\n",
        "transformed parameters{\n",
        "    real mu= alpha1 + alpha2;\n",
        "}\n",
        "model{\n",
        "    sigma ~ cauchy( 0 , 1 );\n",
        "    y ~ normal( mu , sigma );\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ypIcjb-GS0ga",
      "metadata": {
        "id": "ypIcjb-GS0ga"
      },
      "source": [
        "Let us run `Stan`'s Hamiltonian Monte Carlo algorithm for $1000$ iterations that include $400$ warmup iterations. Setup two Hamiltonian Monte Carlo chains and initialise both chains at $(\\mu=0, \\sigma=1)$. Then make a trace plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lbdGzEhMS4eu",
      "metadata": {
        "id": "lbdGzEhMS4eu"
      },
      "outputs": [],
      "source": [
        "# TODO: Write the Stan model to a file\n",
        "\n",
        "# TODO: Compile the Stan model using CmdStanPy\n",
        "\n",
        "# TODO: Sample from the posterior distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mquxW7r2T69d",
      "metadata": {
        "id": "mquxW7r2T69d"
      },
      "outputs": [],
      "source": [
        "# TODO: Create an ArviZ InferenceData object\n",
        "\n",
        "# TODO: Print the summary of the sampling results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044645fc-22a0-4233-a904-15c0b87b8527",
      "metadata": {
        "id": "044645fc-22a0-4233-a904-15c0b87b8527"
      },
      "outputs": [],
      "source": [
        "# TODO: Trace plots\n",
        "\n",
        "# TODO: Save the plot to a PDF file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2zVPKl-MUE3t",
      "metadata": {
        "id": "2zVPKl-MUE3t"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot pairs\n",
        "\n",
        "# TODO: Save the plot to a PDF file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PXCBByMNS43p",
      "metadata": {
        "id": "PXCBByMNS43p"
      },
      "source": [
        "For comparison, let us now consider a model with weakly informative $\\text{Normal}(0,10^2)$ priors on $\\alpha_1$ and $\\alpha_2$. Again, let us run `Stan`'s Hamiltonian Monte Carlo algorithm for $1000$ iterations that include $400$ warmup iterations. Setup two Hamiltonian Monte Carlo chains and initialise both chains at $(\\alpha_1=0, \\alpha_2=0, \\sigma=1)$. Then make a trace plot, and also a pair plot as shown above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1jo3OOSbS9ed",
      "metadata": {
        "id": "1jo3OOSbS9ed"
      },
      "outputs": [],
      "source": [
        "# specify Stan model with unidentifiable parameters and flat prior\n",
        "model5_text = \"\"\"\n",
        "data{\n",
        "    int<lower=1> N;\n",
        "    array [N] real y;\n",
        "}\n",
        "parameters{\n",
        "    real alpha1;\n",
        "    real alpha2;\n",
        "    real<lower=0> sigma;\n",
        "}\n",
        "transformed parameters{\n",
        "    real mu= alpha1 + alpha2;\n",
        "}\n",
        "model{\n",
        "    sigma ~ cauchy( 0 , 1 );\n",
        "    alpha1 ~ normal(0, 10);\n",
        "    alpha2 ~ normal(0, 10);\n",
        "    y ~ normal( mu , sigma );\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qN4GBGM0VFDu",
      "metadata": {
        "id": "qN4GBGM0VFDu"
      },
      "outputs": [],
      "source": [
        "# TODO: Write the Stan model to a file\n",
        "\n",
        "# TODO: Compile the Stan model using CmdStanPy\n",
        "\n",
        "# TODO: Sample from the posterior distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UJYiG585Vbz0",
      "metadata": {
        "id": "UJYiG585Vbz0"
      },
      "outputs": [],
      "source": [
        "# TODO: Create an ArviZ InferenceData object\n",
        "\n",
        "# TODO: Print the summary of the sampling results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c93e49b-cbc7-4619-b870-b853f4a27ede",
      "metadata": {
        "id": "2c93e49b-cbc7-4619-b870-b853f4a27ede"
      },
      "outputs": [],
      "source": [
        "# TODO: Trace plots\n",
        "\n",
        "# TODO: Save the plot to a PDF file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W8VPOsMdVeX1",
      "metadata": {
        "id": "W8VPOsMdVeX1"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot pairs\n",
        "\n",
        "# TODO: Save the plot to a PDF file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pq10wSbES93b",
      "metadata": {
        "id": "pq10wSbES93b"
      },
      "source": [
        "Let us reflect on the trace plots and the pair plots for the different models:\n",
        "\n",
        "- What do you observe in terms of convergence, mixing, and the HMC traces in general?\n",
        "- What does the pair plot reveal to you?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UIfxgLqeYjE7",
      "metadata": {
        "id": "UIfxgLqeYjE7"
      },
      "source": [
        "The first observation is that provided that the prior distributions on model parameters are suitably specified through e.g. weakly informative priors, then Stan's Hamiltonian Monte Carlo algorithm usually works very well to provide us with Monte Carlo samples from the joint posterior distribution.\n",
        "\n",
        "The second observation is related to the pairs plot. We can see that several parameters are extremely highly correlated. In fact, the posterior alpha1 is essentially equal to -alpha2. This means that the joint posterior distribution is essentially concentrated on a hyperplane, a set of measure zero. Yet, Stan's algorithm understands the geometry of the posterior distribution, and can efficiently sample from it. This would be very difficult with a standard Metropolis Hastings algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tFdDWeGLbb3I",
      "metadata": {
        "id": "tFdDWeGLbb3I"
      },
      "source": [
        "## Hello world example using `pystan`\n",
        "\n",
        "Finally, we revisit our Hello World example to see how exactly each step above can be implemented with `pystan`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hEOskNZVMBAI",
      "metadata": {
        "id": "hEOskNZVMBAI"
      },
      "outputs": [],
      "source": [
        "!pip install pystan nest-asyncio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28e70f51-0194-4832-ab41-2a4f933d29e6",
      "metadata": {
        "id": "28e70f51-0194-4832-ab41-2a4f933d29e6"
      },
      "source": [
        "Running in `pystan` in a notebook is problematic since Jupyter blocks certain asyncio functions. To address this problem, we use `nest-asyncio`.\n",
        "\n",
        "See this [`pystan` FAQ](https://pystan.readthedocs.io/en/latest/faq.html) for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aAsMU_BzbHf4",
      "metadata": {
        "id": "aAsMU_BzbHf4"
      },
      "outputs": [],
      "source": [
        "import stan\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "txnn7rV-ak_D",
      "metadata": {
        "id": "txnn7rV-ak_D"
      },
      "outputs": [],
      "source": [
        "# Make data\n",
        "np.random.seed(10680)  # Use your birth date\n",
        "y = np.random.normal(0, 1, 100)  # Generate random data\n",
        "\n",
        "stan_data = {\n",
        "    'N': len(y),\n",
        "    'y': y\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kul6pK7Wa3qK",
      "metadata": {
        "id": "Kul6pK7Wa3qK"
      },
      "outputs": [],
      "source": [
        "# Stan model code (using the same 'model1.stan' as in your R code)\n",
        "pystan_model1_text = \"\"\"\n",
        "data{\n",
        "    int<lower=1> N;\n",
        "    array[N] real y;\n",
        "}\n",
        "parameters{\n",
        "    real mu;\n",
        "    real<lower=0> sigma;\n",
        "}\n",
        "model{\n",
        "    sigma ~ cauchy( 0 , 1 );\n",
        "    mu ~ normal( 0 , 10 );\n",
        "    y ~ normal( mu , sigma );\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SpLnu3Wma5k9",
      "metadata": {
        "id": "SpLnu3Wma5k9"
      },
      "outputs": [],
      "source": [
        "# Compile the model - note we do not need to save the text\n",
        "model = stan.build(pystan_model1_text, data=stan_data, random_seed=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZnSKuS2Ufl8s",
      "metadata": {
        "id": "ZnSKuS2Ufl8s"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "model1_pystan_fit = model.sample(num_chains=2,\n",
        "                                 num_samples=4000,\n",
        "                                 num_warmup=1000,\n",
        "                                 save_warmup=True,\n",
        "                                 init=[{'mu': 1, 'sigma': 2},\n",
        "                                       {'mu': -1, 'sigma': 0.5}])\n",
        "\n",
        "# Save the output to a file\n",
        "with open(\"model1_pystan_fit.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model1_pystan_fit, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bR9lBxuXbFs0",
      "metadata": {
        "id": "bR9lBxuXbFs0"
      },
      "outputs": [],
      "source": [
        "# Print the summary of the sampling results\n",
        "model1_pystan_fit_az_idata = az.from_pystan(model1_pystan_fit, save_warmup=True)\n",
        "\n",
        "model1_pystan_fit_az_idata\n",
        "\n",
        "# Get summary statistics, including 2.75% and 97.5% quantiles\n",
        "summary_stats = az.summary(model1_pystan_fit_az_idata,\n",
        "                           var_names=[\"mu\", \"sigma\"],\n",
        "                           group=\"posterior\",\n",
        "                           hdi_prob=0.95,\n",
        "                           kind=\"all\"# 95% highest density interval\n",
        "                           )\n",
        "\n",
        "summary_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MlUuvBfkiYqj",
      "metadata": {
        "id": "MlUuvBfkiYqj"
      },
      "outputs": [],
      "source": [
        "# To plot traces and assess convergence, extract\n",
        "# Monte Carlo samples including warmup in default\n",
        "# array format that keeps all chains separate\n",
        "\n",
        "# It's often helpful to plot the log posterior density too. Since it is a\n",
        "# sample stat and arviz can only access one group at a time, we will manually\n",
        "# add it to make it easier to view everything together\n",
        "model1_pystan_fit_az_idata[\"posterior\"][\"lp\"] = model1_pystan_fit_az_idata[\"sample_stats\"][\"lp\"]\n",
        "model1_pars = [\"mu\", \"sigma\"]\n",
        "model1_pars_with_lp = model1_pars + [\"lp\"]\n",
        "\n",
        "# Print summary of the parameters\n",
        "summary_stats = az.summary(model1_pystan_fit_az_idata,\n",
        "                           var_names=model1_pars_with_lp,\n",
        "                           group=\"posterior\",\n",
        "                           hdi_prob=0.95,\n",
        "                           kind=\"all\"\n",
        "                          )\n",
        "\n",
        "summary_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iPI1qLM3jSEZ",
      "metadata": {
        "id": "iPI1qLM3jSEZ"
      },
      "outputs": [],
      "source": [
        "# Plot trace for parameters (mu, sigma, and lp)\n",
        "# different colours are different chains\n",
        "az.plot_trace(model1_pystan_fit_az_idata,\n",
        "              filter_vars=\"like\",\n",
        "              var_names=model1_pars_with_lp,\n",
        "              combined=False,\n",
        "              compact=False,\n",
        "              kind=\"trace\",\n",
        "              figsize=(11, 10))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Save the plot to a PDF file\n",
        "plt.savefig(output_dir.joinpath(\"model1_pystan_trace_arviz.pdf\"),\n",
        "            format=\"pdf\",\n",
        "            bbox_inches=\"tight\")\n",
        "\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9csqewQCjTSj",
      "metadata": {
        "id": "9csqewQCjTSj"
      },
      "outputs": [],
      "source": [
        "# Extract the posterior samples excluding warmup\n",
        "# Make the pairs plot (including log-posterior)\n",
        "az.plot_pair(model1_pystan_fit_az_idata,\n",
        "             var_names=model1_pars_with_lp,\n",
        "             marginals=True,\n",
        "             figsize=(13, 8))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.savefig(output_dir.joinpath(\"model1_pystan_pairsplot.pdf\"),\n",
        "            format=\"pdf\", bbox_inches=\"tight\")\n",
        "plt.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}